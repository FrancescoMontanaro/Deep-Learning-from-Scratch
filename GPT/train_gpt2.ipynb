{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from src.utils import device\n",
    "from src.architectures.gpt import GPT2, GPTConfig, Tokenizer, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "dataset_path = os.path.join(os.getcwd(), 'dataset', 'divina_commedia.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 1024 # Batch size for training\n",
    "\n",
    "# Micro batch size for gradient accumulation. This is the number of batches to accumulate gradients before backpropagating.\n",
    "# This is useful when the batch size is too large to fit into memory, so we split the batch into smaller micro batches and accumulate the gradients before backpropagating\n",
    "micro_batch_size = 4\n",
    "\n",
    "epochs = 500 # Number of training epochs\n",
    "sequence_length = 32 # Number of tokens in each training sequence\n",
    "train_val_split = 0.1 # Percentage of training data to use for validation\n",
    "learning_rate = 3e-4 # Learning rate for the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(1337);\n",
    "\n",
    "# Reduce the precision for the matmul operator to improve performance\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the tokenizer\n",
    "tokenizer = Tokenizer('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:  106392\n",
      "Validation set size:  11821\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the data loader\n",
    "data_loader = DataLoader(\n",
    "    txt_file = dataset_path,\n",
    "    tokenizer = tokenizer,\n",
    "    train_val_split = train_val_split,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "# Print the dataset statistics\n",
    "print(\"Training set size: \", len(data_loader.train_tokens))\n",
    "print(\"Validation set size: \", len(data_loader.val_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model configuration\n",
    "# The vocabulary size is 50304, instead of the classic 50257 if the gpt2 tokenizer,\n",
    "# because we add some padding tokens to the vocabulary in order to make the vocabulary \n",
    "# size a multiple of 8 in order to improve performance when using FP16 training.\n",
    "model_config = GPTConfig(\n",
    "    context_size = 1024,\n",
    "    vocab_size = 50304,\n",
    "    n_blocks = 12,\n",
    "    n_heads = 12,\n",
    "    n_embed = 768\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the GPT-2 model\n",
    "gpt2 = GPT2(model_config)\n",
    "\n",
    "# Move the model to the GPU if available \n",
    "# and set the precision to bfloat16 for improved performance\n",
    "gpt2 = gpt2.to(torch.bfloat16).to(device)\n",
    "\n",
    "# Compile the model to optimize performance\n",
    "gpt2 = torch.compile(gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 | Avg step duration: 530.82 ms/step | Epoch duration: 2728.07 ms/epoch --> loss: 10.1875 - val_loss: 9.1977\n",
      "Epoch 2/500 | Avg step duration: 426.94 ms/step | Epoch duration: 2414.28 ms/epoch --> loss: 9.0000 - val_loss: 8.4579\n",
      "Epoch 3/500 | Avg step duration: 424.04 ms/step | Epoch duration: 2406.24 ms/epoch --> loss: 8.1875 - val_loss: 7.7096\n",
      "Epoch 4/500 | Avg step duration: 424.81 ms/step | Epoch duration: 2426.40 ms/epoch --> loss: 7.4062 - val_loss: 7.2082\n",
      "Epoch 5/500 | Avg step duration: 426.11 ms/step | Epoch duration: 2413.45 ms/epoch --> loss: 6.9062 - val_loss: 6.6579\n",
      "Epoch 6/500 | Avg step duration: 424.55 ms/step | Epoch duration: 2408.31 ms/epoch --> loss: 6.5000 - val_loss: 6.3913\n",
      "Epoch 7/500 | Avg step duration: 429.19 ms/step | Epoch duration: 2437.44 ms/epoch --> loss: 6.2500 - val_loss: 6.2836\n",
      "Epoch 8/500 | Avg step duration: 423.94 ms/step | Epoch duration: 2406.37 ms/epoch --> loss: 6.2500 - val_loss: 6.2313\n",
      "Epoch 9/500 | Avg step duration: 423.57 ms/step | Epoch duration: 2420.41 ms/epoch --> loss: 6.0938 - val_loss: 6.2123\n",
      "Epoch 10/500 | Avg step duration: 430.17 ms/step | Epoch duration: 2425.55 ms/epoch --> loss: 6.1250 - val_loss: 6.2184\n",
      "Epoch 11/500 | Avg step duration: 426.05 ms/step | Epoch duration: 2413.24 ms/epoch --> loss: 6.0938 - val_loss: 6.1345\n",
      "Epoch 12/500 | Avg step duration: 423.16 ms/step | Epoch duration: 2417.22 ms/epoch --> loss: 6.0000 - val_loss: 6.0802\n",
      "Epoch 13/500 | Avg step duration: 427.72 ms/step | Epoch duration: 2418.77 ms/epoch --> loss: 5.9688 - val_loss: 6.0639\n",
      "Epoch 14/500 | Avg step duration: 424.70 ms/step | Epoch duration: 2408.61 ms/epoch --> loss: 5.9062 - val_loss: 6.0197\n",
      "Epoch 15/500 | Avg step duration: 424.73 ms/step | Epoch duration: 2427.87 ms/epoch --> loss: 6.0000 - val_loss: 5.9983\n",
      "Epoch 16/500 | Avg step duration: 425.27 ms/step | Epoch duration: 2411.03 ms/epoch --> loss: 5.8438 - val_loss: 5.9497\n",
      "Epoch 17/500 | Avg step duration: 424.26 ms/step | Epoch duration: 2408.49 ms/epoch --> loss: 5.8438 - val_loss: 5.9222\n",
      "Epoch 18/500 | Avg step duration: 424.07 ms/step | Epoch duration: 2411.61 ms/epoch --> loss: 5.7500 - val_loss: 5.8869\n",
      "Epoch 19/500 | Avg step duration: 434.08 ms/step | Epoch duration: 2436.97 ms/epoch --> loss: 5.8438 - val_loss: 5.8356\n",
      "Epoch 20/500 | Avg step duration: 423.91 ms/step | Epoch duration: 2413.34 ms/epoch --> loss: 5.6562 - val_loss: 5.8247\n",
      "Epoch 21/500 | Avg step duration: 427.82 ms/step | Epoch duration: 2420.34 ms/epoch --> loss: 5.7500 - val_loss: 5.7252\n",
      "Epoch 22/500 | Avg step duration: 423.77 ms/step | Epoch duration: 2406.07 ms/epoch --> loss: 5.5938 - val_loss: 5.7238\n",
      "Epoch 23/500 | Avg step duration: 424.35 ms/step | Epoch duration: 2421.22 ms/epoch --> loss: 5.5938 - val_loss: 5.7028\n",
      "Epoch 24/500 | Avg step duration: 424.43 ms/step | Epoch duration: 2407.06 ms/epoch --> loss: 5.6250 - val_loss: 5.6865\n",
      "Epoch 25/500 | Avg step duration: 430.05 ms/step | Epoch duration: 2421.88 ms/epoch --> loss: 5.5000 - val_loss: 5.6484\n",
      "Epoch 26/500 | Avg step duration: 424.16 ms/step | Epoch duration: 2422.24 ms/epoch --> loss: 5.5000 - val_loss: 5.5618\n",
      "Epoch 27/500 | Avg step duration: 432.06 ms/step | Epoch duration: 2430.30 ms/epoch --> loss: 5.4062 - val_loss: 5.5982\n",
      "Epoch 28/500 | Avg step duration: 421.85 ms/step | Epoch duration: 2398.95 ms/epoch --> loss: 5.4062 - val_loss: 5.4973\n",
      "Epoch 29/500 | Avg step duration: 423.63 ms/step | Epoch duration: 2403.48 ms/epoch --> loss: 5.2812 - val_loss: 5.5058\n",
      "Epoch 30/500 | Avg step duration: 434.44 ms/step | Epoch duration: 2436.13 ms/epoch --> loss: 5.3438 - val_loss: 5.4623\n",
      "Epoch 31/500 | Avg step duration: 424.31 ms/step | Epoch duration: 2419.16 ms/epoch --> loss: 5.3438 - val_loss: 5.4474\n",
      "Epoch 32/500 | Avg step duration: 424.23 ms/step | Epoch duration: 2406.83 ms/epoch --> loss: 5.2812 - val_loss: 5.4555\n",
      "Epoch 33/500 | Avg step duration: 422.65 ms/step | Epoch duration: 2404.09 ms/epoch --> loss: 5.2188 - val_loss: 5.3784\n",
      "Epoch 34/500 | Avg step duration: 422.06 ms/step | Epoch duration: 2401.08 ms/epoch --> loss: 5.2812 - val_loss: 5.4402\n",
      "Epoch 35/500 | Avg step duration: 428.01 ms/step | Epoch duration: 2418.11 ms/epoch --> loss: 5.2812 - val_loss: 5.3213\n",
      "Epoch 36/500 | Avg step duration: 429.01 ms/step | Epoch duration: 2432.16 ms/epoch --> loss: 5.2188 - val_loss: 5.3363\n",
      "Epoch 37/500 | Avg step duration: 424.70 ms/step | Epoch duration: 2406.37 ms/epoch --> loss: 5.1250 - val_loss: 5.2649\n",
      "Epoch 38/500 | Avg step duration: 425.47 ms/step | Epoch duration: 2414.63 ms/epoch --> loss: 5.1875 - val_loss: 5.2432\n",
      "Epoch 39/500 | Avg step duration: 423.11 ms/step | Epoch duration: 2417.27 ms/epoch --> loss: 5.1562 - val_loss: 5.2955\n",
      "Epoch 40/500 | Avg step duration: 423.90 ms/step | Epoch duration: 2402.92 ms/epoch --> loss: 5.0938 - val_loss: 5.2632\n",
      "Epoch 41/500 | Avg step duration: 440.28 ms/step | Epoch duration: 2474.45 ms/epoch --> loss: 5.0938 - val_loss: 5.2463\n",
      "Epoch 42/500 | Avg step duration: 425.92 ms/step | Epoch duration: 2420.36 ms/epoch --> loss: 5.0625 - val_loss: 5.2140\n",
      "Epoch 43/500 | Avg step duration: 431.33 ms/step | Epoch duration: 2426.81 ms/epoch --> loss: 4.9688 - val_loss: 5.1970\n",
      "Epoch 44/500 | Avg step duration: 425.00 ms/step | Epoch duration: 2414.56 ms/epoch --> loss: 5.0938 - val_loss: 5.2058\n",
      "Epoch 45/500 | Avg step duration: 424.12 ms/step | Epoch duration: 2431.06 ms/epoch --> loss: 5.0312 - val_loss: 5.1158\n",
      "Epoch 46/500 | Avg step duration: 423.50 ms/step | Epoch duration: 2403.59 ms/epoch --> loss: 5.0938 - val_loss: 5.1264\n",
      "Epoch 47/500 | Avg step duration: 422.93 ms/step | Epoch duration: 2402.22 ms/epoch --> loss: 5.0000 - val_loss: 5.1722\n",
      "Epoch 48/500 | Avg step duration: 422.76 ms/step | Epoch duration: 2402.79 ms/epoch --> loss: 5.0312 - val_loss: 5.0863\n",
      "Epoch 49/500 | Avg step duration: 424.67 ms/step | Epoch duration: 2415.37 ms/epoch --> loss: 4.9688 - val_loss: 5.1067\n",
      "Epoch 50/500 | Avg step duration: 424.46 ms/step | Epoch duration: 2410.94 ms/epoch --> loss: 4.9688 - val_loss: 5.0924\n",
      "Epoch 51/500 | Avg step duration: 425.32 ms/step | Epoch duration: 2431.30 ms/epoch --> loss: 5.0312 - val_loss: 5.0408\n",
      "Epoch 52/500 | Avg step duration: 425.04 ms/step | Epoch duration: 2415.32 ms/epoch --> loss: 5.0000 - val_loss: 5.0560\n",
      "Epoch 53/500 | Avg step duration: 425.12 ms/step | Epoch duration: 2407.91 ms/epoch --> loss: 4.9062 - val_loss: 5.0975\n",
      "Epoch 54/500 | Avg step duration: 429.03 ms/step | Epoch duration: 2421.24 ms/epoch --> loss: 4.9062 - val_loss: 5.0476\n",
      "Epoch 55/500 | Avg step duration: 421.69 ms/step | Epoch duration: 2391.97 ms/epoch --> loss: 4.8438 - val_loss: 4.9966\n",
      "Epoch 56/500 | Avg step duration: 421.87 ms/step | Epoch duration: 2398.41 ms/epoch --> loss: 4.8438 - val_loss: 5.0336\n",
      "Epoch 57/500 | Avg step duration: 436.22 ms/step | Epoch duration: 2446.15 ms/epoch --> loss: 4.8438 - val_loss: 5.0747\n",
      "Epoch 58/500 | Avg step duration: 424.46 ms/step | Epoch duration: 2407.64 ms/epoch --> loss: 4.9375 - val_loss: 5.0319\n",
      "Epoch 59/500 | Avg step duration: 429.18 ms/step | Epoch duration: 2420.96 ms/epoch --> loss: 4.7500 - val_loss: 5.0031\n",
      "Epoch 60/500 | Avg step duration: 424.16 ms/step | Epoch duration: 2411.10 ms/epoch --> loss: 4.8438 - val_loss: 4.9776\n",
      "Epoch 61/500 | Avg step duration: 425.76 ms/step | Epoch duration: 2409.04 ms/epoch --> loss: 4.8438 - val_loss: 4.9864\n",
      "Epoch 62/500 | Avg step duration: 423.51 ms/step | Epoch duration: 2439.94 ms/epoch --> loss: 4.7812 - val_loss: 4.9623\n",
      "Epoch 63/500 | Avg step duration: 423.72 ms/step | Epoch duration: 2414.55 ms/epoch --> loss: 4.7812 - val_loss: 4.9243\n",
      "Epoch 64/500 | Avg step duration: 423.97 ms/step | Epoch duration: 2405.10 ms/epoch --> loss: 4.6875 - val_loss: 4.9039\n",
      "Epoch 65/500 | Avg step duration: 423.36 ms/step | Epoch duration: 2411.02 ms/epoch --> loss: 4.8438 - val_loss: 4.9168\n",
      "Epoch 66/500 | Avg step duration: 423.84 ms/step | Epoch duration: 2404.35 ms/epoch --> loss: 4.7500 - val_loss: 4.9487\n",
      "Epoch 67/500 | Avg step duration: 424.92 ms/step | Epoch duration: 2414.44 ms/epoch --> loss: 4.7812 - val_loss: 4.9293\n",
      "Epoch 68/500 | Avg step duration: 424.18 ms/step | Epoch duration: 2423.96 ms/epoch --> loss: 4.7812 - val_loss: 4.9246\n",
      "Epoch 69/500 | Avg step duration: 426.16 ms/step | Epoch duration: 2404.39 ms/epoch --> loss: 4.6250 - val_loss: 4.8675\n",
      "Epoch 70/500 | Avg step duration: 422.43 ms/step | Epoch duration: 2402.04 ms/epoch --> loss: 4.6250 - val_loss: 4.8533\n",
      "Epoch 71/500 | Avg step duration: 422.29 ms/step | Epoch duration: 2394.31 ms/epoch --> loss: 4.6562 - val_loss: 4.8342\n",
      "Epoch 72/500 | Avg step duration: 451.72 ms/step | Epoch duration: 2488.60 ms/epoch --> loss: 4.6250 - val_loss: 4.8190\n",
      "Epoch 73/500 | Avg step duration: 423.09 ms/step | Epoch duration: 2407.81 ms/epoch --> loss: 4.6562 - val_loss: 4.8811\n",
      "Epoch 74/500 | Avg step duration: 422.63 ms/step | Epoch duration: 2428.24 ms/epoch --> loss: 4.6562 - val_loss: 4.8132\n",
      "Epoch 75/500 | Avg step duration: 424.11 ms/step | Epoch duration: 2406.65 ms/epoch --> loss: 4.7188 - val_loss: 4.8529\n",
      "Epoch 76/500 | Avg step duration: 422.78 ms/step | Epoch duration: 2413.58 ms/epoch --> loss: 4.5938 - val_loss: 4.8118\n",
      "Epoch 77/500 | Avg step duration: 423.12 ms/step | Epoch duration: 2400.11 ms/epoch --> loss: 4.6875 - val_loss: 4.8128\n",
      "Epoch 78/500 | Avg step duration: 423.89 ms/step | Epoch duration: 2404.15 ms/epoch --> loss: 4.5938 - val_loss: 4.8074\n",
      "Epoch 79/500 | Avg step duration: 423.47 ms/step | Epoch duration: 2401.80 ms/epoch --> loss: 4.6250 - val_loss: 4.8193\n",
      "Epoch 80/500 | Avg step duration: 429.67 ms/step | Epoch duration: 2434.93 ms/epoch --> loss: 4.5312 - val_loss: 4.7928\n",
      "Epoch 81/500 | Avg step duration: 423.44 ms/step | Epoch duration: 2408.29 ms/epoch --> loss: 4.5938 - val_loss: 4.7717\n",
      "Epoch 82/500 | Avg step duration: 424.40 ms/step | Epoch duration: 2406.18 ms/epoch --> loss: 4.5625 - val_loss: 4.7972\n",
      "Epoch 83/500 | Avg step duration: 422.79 ms/step | Epoch duration: 2401.45 ms/epoch --> loss: 4.5000 - val_loss: 4.7432\n",
      "Epoch 84/500 | Avg step duration: 423.69 ms/step | Epoch duration: 2404.85 ms/epoch --> loss: 4.5312 - val_loss: 4.7663\n",
      "Epoch 85/500 | Avg step duration: 431.28 ms/step | Epoch duration: 2426.75 ms/epoch --> loss: 4.5000 - val_loss: 4.7942\n",
      "Epoch 86/500 | Avg step duration: 423.49 ms/step | Epoch duration: 2432.44 ms/epoch --> loss: 4.4688 - val_loss: 4.8060\n",
      "Epoch 87/500 | Avg step duration: 424.38 ms/step | Epoch duration: 2406.43 ms/epoch --> loss: 4.5312 - val_loss: 4.7565\n",
      "Epoch 88/500 | Avg step duration: 424.97 ms/step | Epoch duration: 2408.70 ms/epoch --> loss: 4.6250 - val_loss: 4.7700\n",
      "Epoch 89/500 | Avg step duration: 423.43 ms/step | Epoch duration: 2411.31 ms/epoch --> loss: 4.4688 - val_loss: 4.6848\n",
      "Epoch 90/500 | Avg step duration: 423.11 ms/step | Epoch duration: 2402.40 ms/epoch --> loss: 4.5938 - val_loss: 4.8200\n",
      "Epoch 91/500 | Avg step duration: 423.83 ms/step | Epoch duration: 2424.42 ms/epoch --> loss: 4.5000 - val_loss: 4.7296\n",
      "Epoch 92/500 | Avg step duration: 425.06 ms/step | Epoch duration: 2434.94 ms/epoch --> loss: 4.4688 - val_loss: 4.7391\n",
      "Epoch 93/500 | Avg step duration: 425.89 ms/step | Epoch duration: 2411.45 ms/epoch --> loss: 4.4688 - val_loss: 4.6427\n",
      "Epoch 94/500 | Avg step duration: 423.80 ms/step | Epoch duration: 2419.12 ms/epoch --> loss: 4.4688 - val_loss: 4.6821\n",
      "Epoch 95/500 | Avg step duration: 424.75 ms/step | Epoch duration: 2407.06 ms/epoch --> loss: 4.4062 - val_loss: 4.6821\n",
      "Epoch 96/500 | Avg step duration: 423.66 ms/step | Epoch duration: 2419.36 ms/epoch --> loss: 4.3750 - val_loss: 4.6107\n",
      "Epoch 97/500 | Avg step duration: 424.18 ms/step | Epoch duration: 2412.90 ms/epoch --> loss: 4.4062 - val_loss: 4.6709\n",
      "Epoch 98/500 | Avg step duration: 424.38 ms/step | Epoch duration: 2424.57 ms/epoch --> loss: 4.4062 - val_loss: 4.6338\n",
      "Epoch 99/500 | Avg step duration: 424.05 ms/step | Epoch duration: 2405.77 ms/epoch --> loss: 4.4375 - val_loss: 4.6525\n",
      "Epoch 100/500 | Avg step duration: 424.51 ms/step | Epoch duration: 2406.68 ms/epoch --> loss: 4.4062 - val_loss: 4.6851\n",
      "Epoch 101/500 | Avg step duration: 427.98 ms/step | Epoch duration: 2415.77 ms/epoch --> loss: 4.4062 - val_loss: 4.6829\n",
      "Epoch 102/500 | Avg step duration: 423.99 ms/step | Epoch duration: 2408.73 ms/epoch --> loss: 4.3438 - val_loss: 4.6632\n",
      "Epoch 103/500 | Avg step duration: 425.06 ms/step | Epoch duration: 2408.80 ms/epoch --> loss: 4.2812 - val_loss: 4.6753\n",
      "Epoch 104/500 | Avg step duration: 423.89 ms/step | Epoch duration: 2404.84 ms/epoch --> loss: 4.4062 - val_loss: 4.6112\n",
      "Epoch 105/500 | Avg step duration: 428.82 ms/step | Epoch duration: 2429.75 ms/epoch --> loss: 4.3750 - val_loss: 4.5442\n",
      "Epoch 106/500 | Avg step duration: 425.24 ms/step | Epoch duration: 2408.97 ms/epoch --> loss: 4.3750 - val_loss: 4.6352\n",
      "Epoch 107/500 | Avg step duration: 423.34 ms/step | Epoch duration: 2432.77 ms/epoch --> loss: 4.2500 - val_loss: 4.5871\n",
      "Epoch 108/500 | Avg step duration: 425.15 ms/step | Epoch duration: 2408.10 ms/epoch --> loss: 4.3750 - val_loss: 4.5995\n",
      "Epoch 109/500 | Avg step duration: 425.06 ms/step | Epoch duration: 2407.66 ms/epoch --> loss: 4.4062 - val_loss: 4.5481\n",
      "Epoch 110/500 | Avg step duration: 423.94 ms/step | Epoch duration: 2419.44 ms/epoch --> loss: 4.2500 - val_loss: 4.5718\n",
      "Epoch 111/500 | Avg step duration: 429.83 ms/step | Epoch duration: 2423.00 ms/epoch --> loss: 4.3125 - val_loss: 4.6084\n",
      "Epoch 112/500 | Avg step duration: 424.08 ms/step | Epoch duration: 2405.00 ms/epoch --> loss: 4.2500 - val_loss: 4.5294\n",
      "Epoch 113/500 | Avg step duration: 423.78 ms/step | Epoch duration: 2404.45 ms/epoch --> loss: 4.4062 - val_loss: 4.5667\n",
      "Epoch 114/500 | Avg step duration: 427.90 ms/step | Epoch duration: 2417.30 ms/epoch --> loss: 4.3750 - val_loss: 4.5953\n",
      "Epoch 115/500 | Avg step duration: 424.14 ms/step | Epoch duration: 2415.97 ms/epoch --> loss: 4.1562 - val_loss: 4.5207\n",
      "Epoch 116/500 | Avg step duration: 424.32 ms/step | Epoch duration: 2404.86 ms/epoch --> loss: 4.2500 - val_loss: 4.4672\n",
      "Epoch 117/500 | Avg step duration: 428.90 ms/step | Epoch duration: 2419.66 ms/epoch --> loss: 4.2500 - val_loss: 4.5279\n",
      "Epoch 118/500 | Avg step duration: 423.64 ms/step | Epoch duration: 2405.94 ms/epoch --> loss: 4.2188 - val_loss: 4.5707\n",
      "Epoch 119/500 | Avg step duration: 429.45 ms/step | Epoch duration: 2421.81 ms/epoch --> loss: 4.3125 - val_loss: 4.5166\n",
      "Epoch 120/500 | Avg step duration: 423.20 ms/step | Epoch duration: 2418.20 ms/epoch --> loss: 4.2812 - val_loss: 4.5139\n",
      "Epoch 121/500 | Avg step duration: 425.91 ms/step | Epoch duration: 2411.57 ms/epoch --> loss: 4.3438 - val_loss: 4.4764\n",
      "Epoch 122/500 | Avg step duration: 424.42 ms/step | Epoch duration: 2406.38 ms/epoch --> loss: 4.2500 - val_loss: 4.5340\n",
      "Epoch 123/500 | Avg step duration: 427.09 ms/step | Epoch duration: 2421.48 ms/epoch --> loss: 4.1562 - val_loss: 4.5248\n",
      "Epoch 124/500 | Avg step duration: 426.72 ms/step | Epoch duration: 2413.78 ms/epoch --> loss: 4.1562 - val_loss: 4.5479\n",
      "Epoch 125/500 | Avg step duration: 424.52 ms/step | Epoch duration: 2413.18 ms/epoch --> loss: 4.2188 - val_loss: 4.5034\n",
      "Epoch 126/500 | Avg step duration: 423.11 ms/step | Epoch duration: 2402.28 ms/epoch --> loss: 4.0938 - val_loss: 4.4642\n",
      "Epoch 127/500 | Avg step duration: 428.98 ms/step | Epoch duration: 2417.45 ms/epoch --> loss: 4.1562 - val_loss: 4.4372\n",
      "Epoch 128/500 | Avg step duration: 424.49 ms/step | Epoch duration: 2417.53 ms/epoch --> loss: 4.2188 - val_loss: 4.4528\n",
      "Epoch 129/500 | Avg step duration: 428.40 ms/step | Epoch duration: 2418.11 ms/epoch --> loss: 4.1250 - val_loss: 4.4351\n",
      "Epoch 130/500 | Avg step duration: 428.61 ms/step | Epoch duration: 2418.65 ms/epoch --> loss: 4.1250 - val_loss: 4.4696\n",
      "Epoch 131/500 | Avg step duration: 423.63 ms/step | Epoch duration: 2418.41 ms/epoch --> loss: 4.1562 - val_loss: 4.4333\n",
      "Epoch 132/500 | Avg step duration: 424.70 ms/step | Epoch duration: 2410.15 ms/epoch --> loss: 4.1562 - val_loss: 4.4941\n",
      "Epoch 133/500 | Avg step duration: 423.36 ms/step | Epoch duration: 2406.42 ms/epoch --> loss: 4.0938 - val_loss: 4.4613\n",
      "Epoch 134/500 | Avg step duration: 423.72 ms/step | Epoch duration: 2404.85 ms/epoch --> loss: 4.1875 - val_loss: 4.4868\n",
      "Epoch 135/500 | Avg step duration: 426.97 ms/step | Epoch duration: 2407.39 ms/epoch --> loss: 4.0312 - val_loss: 4.4757\n",
      "Epoch 136/500 | Avg step duration: 423.06 ms/step | Epoch duration: 2413.36 ms/epoch --> loss: 4.0938 - val_loss: 4.4856\n",
      "Epoch 137/500 | Avg step duration: 424.79 ms/step | Epoch duration: 2407.80 ms/epoch --> loss: 4.1250 - val_loss: 4.4336\n",
      "Epoch 138/500 | Avg step duration: 424.19 ms/step | Epoch duration: 2420.90 ms/epoch --> loss: 4.0312 - val_loss: 4.4205\n",
      "Epoch 139/500 | Avg step duration: 424.72 ms/step | Epoch duration: 2407.25 ms/epoch --> loss: 4.1250 - val_loss: 4.4479\n",
      "Epoch 140/500 | Avg step duration: 425.56 ms/step | Epoch duration: 2425.39 ms/epoch --> loss: 4.1250 - val_loss: 4.4107\n",
      "Epoch 141/500 | Avg step duration: 423.37 ms/step | Epoch duration: 2425.42 ms/epoch --> loss: 4.0938 - val_loss: 4.4307\n",
      "Epoch 142/500 | Avg step duration: 424.00 ms/step | Epoch duration: 2405.06 ms/epoch --> loss: 4.2188 - val_loss: 4.3528\n",
      "Epoch 143/500 | Avg step duration: 423.79 ms/step | Epoch duration: 2408.78 ms/epoch --> loss: 3.9531 - val_loss: 4.4115\n",
      "Epoch 144/500 | Avg step duration: 423.34 ms/step | Epoch duration: 2404.92 ms/epoch --> loss: 4.0938 - val_loss: 4.3908\n",
      "Epoch 145/500 | Avg step duration: 428.45 ms/step | Epoch duration: 2419.08 ms/epoch --> loss: 4.0938 - val_loss: 4.4399\n",
      "Epoch 146/500 | Avg step duration: 423.27 ms/step | Epoch duration: 2434.57 ms/epoch --> loss: 4.0312 - val_loss: 4.3526\n",
      "Epoch 147/500 | Avg step duration: 425.11 ms/step | Epoch duration: 2409.48 ms/epoch --> loss: 3.9375 - val_loss: 4.4113\n",
      "Epoch 148/500 | Avg step duration: 426.16 ms/step | Epoch duration: 2410.74 ms/epoch --> loss: 4.0000 - val_loss: 4.4436\n",
      "Epoch 149/500 | Avg step duration: 423.75 ms/step | Epoch duration: 2418.53 ms/epoch --> loss: 4.0312 - val_loss: 4.3616\n",
      "Epoch 150/500 | Avg step duration: 424.23 ms/step | Epoch duration: 2405.95 ms/epoch --> loss: 4.0312 - val_loss: 4.3801\n",
      "Epoch 151/500 | Avg step duration: 423.38 ms/step | Epoch duration: 2406.87 ms/epoch --> loss: 4.0000 - val_loss: 4.3753\n",
      "Epoch 152/500 | Avg step duration: 427.44 ms/step | Epoch duration: 2444.99 ms/epoch --> loss: 4.1250 - val_loss: 4.3541\n",
      "Epoch 153/500 | Avg step duration: 424.67 ms/step | Epoch duration: 2407.79 ms/epoch --> loss: 3.9531 - val_loss: 4.4047\n",
      "Epoch 154/500 | Avg step duration: 423.30 ms/step | Epoch duration: 2415.31 ms/epoch --> loss: 3.9531 - val_loss: 4.2943\n",
      "Epoch 155/500 | Avg step duration: 424.50 ms/step | Epoch duration: 2406.88 ms/epoch --> loss: 3.9219 - val_loss: 4.3337\n",
      "Epoch 156/500 | Avg step duration: 423.40 ms/step | Epoch duration: 2409.39 ms/epoch --> loss: 4.0312 - val_loss: 4.3519\n",
      "Epoch 157/500 | Avg step duration: 424.25 ms/step | Epoch duration: 2418.58 ms/epoch --> loss: 4.0312 - val_loss: 4.2981\n",
      "Epoch 158/500 | Avg step duration: 424.11 ms/step | Epoch duration: 2420.27 ms/epoch --> loss: 3.9375 - val_loss: 4.3850\n",
      "Epoch 159/500 | Avg step duration: 423.24 ms/step | Epoch duration: 2405.38 ms/epoch --> loss: 3.9375 - val_loss: 4.3471\n",
      "Epoch 160/500 | Avg step duration: 423.75 ms/step | Epoch duration: 2405.97 ms/epoch --> loss: 3.9531 - val_loss: 4.3962\n",
      "Epoch 161/500 | Avg step duration: 425.12 ms/step | Epoch duration: 2411.34 ms/epoch --> loss: 3.9531 - val_loss: 4.3550\n",
      "Epoch 162/500 | Avg step duration: 423.52 ms/step | Epoch duration: 2417.20 ms/epoch --> loss: 3.9531 - val_loss: 4.3969\n",
      "Epoch 163/500 | Avg step duration: 423.86 ms/step | Epoch duration: 2419.00 ms/epoch --> loss: 3.9844 - val_loss: 4.3779\n",
      "Epoch 164/500 | Avg step duration: 426.53 ms/step | Epoch duration: 2436.43 ms/epoch --> loss: 4.0312 - val_loss: 4.3117\n",
      "Epoch 165/500 | Avg step duration: 428.63 ms/step | Epoch duration: 2426.61 ms/epoch --> loss: 3.8594 - val_loss: 4.3854\n",
      "Epoch 166/500 | Avg step duration: 425.40 ms/step | Epoch duration: 2408.86 ms/epoch --> loss: 3.9219 - val_loss: 4.3718\n",
      "Epoch 167/500 | Avg step duration: 424.40 ms/step | Epoch duration: 2407.02 ms/epoch --> loss: 3.8750 - val_loss: 4.2872\n",
      "Epoch 168/500 | Avg step duration: 424.10 ms/step | Epoch duration: 2406.20 ms/epoch --> loss: 3.9219 - val_loss: 4.3251\n",
      "Epoch 169/500 | Avg step duration: 425.51 ms/step | Epoch duration: 2410.87 ms/epoch --> loss: 3.8906 - val_loss: 4.3536\n",
      "Epoch 170/500 | Avg step duration: 429.32 ms/step | Epoch duration: 2434.33 ms/epoch --> loss: 3.8750 - val_loss: 4.3794\n",
      "Epoch 171/500 | Avg step duration: 425.10 ms/step | Epoch duration: 2406.87 ms/epoch --> loss: 3.9219 - val_loss: 4.2580\n",
      "Epoch 172/500 | Avg step duration: 424.41 ms/step | Epoch duration: 2411.25 ms/epoch --> loss: 3.9375 - val_loss: 4.3072\n",
      "Epoch 173/500 | Avg step duration: 424.29 ms/step | Epoch duration: 2406.79 ms/epoch --> loss: 3.8750 - val_loss: 4.2619\n",
      "Epoch 174/500 | Avg step duration: 425.22 ms/step | Epoch duration: 2423.65 ms/epoch --> loss: 3.9531 - val_loss: 4.2976\n",
      "Epoch 175/500 | Avg step duration: 423.81 ms/step | Epoch duration: 2419.03 ms/epoch --> loss: 3.8594 - val_loss: 4.2982\n",
      "Epoch 176/500 | Avg step duration: 432.46 ms/step | Epoch duration: 2446.28 ms/epoch --> loss: 3.8125 - val_loss: 4.3059\n",
      "Epoch 177/500 | Avg step duration: 424.72 ms/step | Epoch duration: 2413.00 ms/epoch --> loss: 3.8125 - val_loss: 4.3872\n",
      "Epoch 178/500 | Avg step duration: 424.11 ms/step | Epoch duration: 2418.69 ms/epoch --> loss: 3.9531 - val_loss: 4.2469\n",
      "Epoch 179/500 | Avg step duration: 425.75 ms/step | Epoch duration: 2408.47 ms/epoch --> loss: 3.8594 - val_loss: 4.2237\n",
      "Epoch 180/500 | Avg step duration: 431.58 ms/step | Epoch duration: 2426.98 ms/epoch --> loss: 3.7500 - val_loss: 4.3550\n",
      "Epoch 181/500 | Avg step duration: 423.98 ms/step | Epoch duration: 2434.28 ms/epoch --> loss: 3.8906 - val_loss: 4.2259\n",
      "Epoch 182/500 | Avg step duration: 424.31 ms/step | Epoch duration: 2406.97 ms/epoch --> loss: 3.8125 - val_loss: 4.2138\n",
      "Epoch 183/500 | Avg step duration: 423.01 ms/step | Epoch duration: 2404.00 ms/epoch --> loss: 3.8281 - val_loss: 4.2366\n",
      "Epoch 184/500 | Avg step duration: 425.25 ms/step | Epoch duration: 2418.71 ms/epoch --> loss: 3.8750 - val_loss: 4.2339\n",
      "Epoch 185/500 | Avg step duration: 426.65 ms/step | Epoch duration: 2412.86 ms/epoch --> loss: 3.8281 - val_loss: 4.2182\n",
      "Epoch 186/500 | Avg step duration: 423.84 ms/step | Epoch duration: 2418.03 ms/epoch --> loss: 3.7969 - val_loss: 4.2466\n",
      "Epoch 187/500 | Avg step duration: 426.13 ms/step | Epoch duration: 2426.84 ms/epoch --> loss: 3.8281 - val_loss: 4.2931\n",
      "Epoch 188/500 | Avg step duration: 425.03 ms/step | Epoch duration: 2408.93 ms/epoch --> loss: 3.9375 - val_loss: 4.2887\n",
      "Epoch 189/500 | Avg step duration: 423.81 ms/step | Epoch duration: 2420.33 ms/epoch --> loss: 3.8125 - val_loss: 4.2655\n",
      "Epoch 190/500 | Avg step duration: 425.18 ms/step | Epoch duration: 2408.48 ms/epoch --> loss: 3.8125 - val_loss: 4.2542\n",
      "Epoch 191/500 | Avg step duration: 424.43 ms/step | Epoch duration: 2407.58 ms/epoch --> loss: 3.7500 - val_loss: 4.2266\n",
      "Epoch 192/500 | Avg step duration: 432.72 ms/step | Epoch duration: 2482.84 ms/epoch --> loss: 3.7500 - val_loss: 4.2142\n",
      "Epoch 193/500 | Avg step duration: 443.83 ms/step | Epoch duration: 2474.75 ms/epoch --> loss: 3.8125 - val_loss: 4.3308\n",
      "Epoch 194/500 | Avg step duration: 427.99 ms/step | Epoch duration: 2419.02 ms/epoch --> loss: 3.8281 - val_loss: 4.2999\n",
      "Epoch 195/500 | Avg step duration: 427.34 ms/step | Epoch duration: 2420.09 ms/epoch --> loss: 3.7969 - val_loss: 4.3161\n",
      "Epoch 196/500 | Avg step duration: 481.51 ms/step | Epoch duration: 2600.67 ms/epoch --> loss: 3.8281 - val_loss: 4.2216\n",
      "Epoch 197/500 | Avg step duration: 426.18 ms/step | Epoch duration: 2415.90 ms/epoch --> loss: 3.8125 - val_loss: 4.2607\n",
      "Epoch 198/500 | Avg step duration: 425.24 ms/step | Epoch duration: 2442.69 ms/epoch --> loss: 3.7969 - val_loss: 4.2556\n",
      "Epoch 199/500 | Avg step duration: 426.56 ms/step | Epoch duration: 2411.99 ms/epoch --> loss: 3.9219 - val_loss: 4.2558\n",
      "Epoch 200/500 | Avg step duration: 429.40 ms/step | Epoch duration: 2426.10 ms/epoch --> loss: 3.7500 - val_loss: 4.2519\n",
      "Epoch 201/500 | Avg step duration: 423.19 ms/step | Epoch duration: 2406.12 ms/epoch --> loss: 3.7969 - val_loss: 4.2356\n",
      "Epoch 202/500 | Avg step duration: 426.17 ms/step | Epoch duration: 2410.41 ms/epoch --> loss: 3.7656 - val_loss: 4.1962\n",
      "Epoch 203/500 | Avg step duration: 423.44 ms/step | Epoch duration: 2417.68 ms/epoch --> loss: 3.7969 - val_loss: 4.2330\n",
      "Epoch 204/500 | Avg step duration: 423.28 ms/step | Epoch duration: 2401.37 ms/epoch --> loss: 3.7344 - val_loss: 4.2040\n",
      "Epoch 205/500 | Avg step duration: 425.51 ms/step | Epoch duration: 2410.10 ms/epoch --> loss: 3.7500 - val_loss: 4.1812\n",
      "Epoch 206/500 | Avg step duration: 422.58 ms/step | Epoch duration: 2418.37 ms/epoch --> loss: 3.7656 - val_loss: 4.2247\n",
      "Epoch 207/500 | Avg step duration: 430.45 ms/step | Epoch duration: 2424.31 ms/epoch --> loss: 3.7656 - val_loss: 4.2527\n",
      "Epoch 208/500 | Avg step duration: 422.88 ms/step | Epoch duration: 2402.76 ms/epoch --> loss: 3.7500 - val_loss: 4.2315\n",
      "Epoch 209/500 | Avg step duration: 422.78 ms/step | Epoch duration: 2401.08 ms/epoch --> loss: 3.7344 - val_loss: 4.2024\n",
      "Epoch 210/500 | Avg step duration: 423.58 ms/step | Epoch duration: 2403.46 ms/epoch --> loss: 3.6875 - val_loss: 4.2799\n",
      "Epoch 211/500 | Avg step duration: 422.99 ms/step | Epoch duration: 2415.69 ms/epoch --> loss: 3.7656 - val_loss: 4.2359\n",
      "Epoch 212/500 | Avg step duration: 424.17 ms/step | Epoch duration: 2403.79 ms/epoch --> loss: 3.7031 - val_loss: 4.2940\n",
      "Epoch 213/500 | Avg step duration: 423.92 ms/step | Epoch duration: 2417.43 ms/epoch --> loss: 3.7344 - val_loss: 4.2237\n",
      "Epoch 214/500 | Avg step duration: 447.03 ms/step | Epoch duration: 2488.22 ms/epoch --> loss: 3.6406 - val_loss: 4.2425\n",
      "Epoch 215/500 | Avg step duration: 487.99 ms/step | Epoch duration: 2705.32 ms/epoch --> loss: 3.6719 - val_loss: 4.2721\n",
      "Epoch 216/500 | Avg step duration: 427.79 ms/step | Epoch duration: 2443.05 ms/epoch --> loss: 3.6719 - val_loss: 4.1790\n",
      "Epoch 217/500 | Avg step duration: 426.98 ms/step | Epoch duration: 2417.88 ms/epoch --> loss: 3.7500 - val_loss: 4.1770\n",
      "Epoch 218/500 | Avg step duration: 444.53 ms/step | Epoch duration: 2503.07 ms/epoch --> loss: 3.7031 - val_loss: 4.2189\n",
      "Epoch 219/500 | Avg step duration: 429.47 ms/step | Epoch duration: 2438.47 ms/epoch --> loss: 3.7031 - val_loss: 4.2733\n",
      "Epoch 220/500 | Avg step duration: 425.59 ms/step | Epoch duration: 2409.85 ms/epoch --> loss: 3.6094 - val_loss: 4.2532\n",
      "Epoch 221/500 | Avg step duration: 424.30 ms/step | Epoch duration: 2423.86 ms/epoch --> loss: 3.7500 - val_loss: 4.2379\n",
      "Epoch 222/500 | Avg step duration: 425.11 ms/step | Epoch duration: 2408.02 ms/epoch --> loss: 3.6094 - val_loss: 4.1872\n",
      "Epoch 223/500 | Avg step duration: 425.00 ms/step | Epoch duration: 2406.15 ms/epoch --> loss: 3.6250 - val_loss: 4.2235\n",
      "Epoch 224/500 | Avg step duration: 422.79 ms/step | Epoch duration: 2420.54 ms/epoch --> loss: 3.6406 - val_loss: 4.1683\n",
      "Epoch 225/500 | Avg step duration: 426.95 ms/step | Epoch duration: 2414.17 ms/epoch --> loss: 3.5469 - val_loss: 4.2475\n",
      "Epoch 226/500 | Avg step duration: 423.56 ms/step | Epoch duration: 2398.92 ms/epoch --> loss: 3.6094 - val_loss: 4.1726\n",
      "Epoch 227/500 | Avg step duration: 424.11 ms/step | Epoch duration: 2405.67 ms/epoch --> loss: 3.7031 - val_loss: 4.1741\n",
      "Epoch 228/500 | Avg step duration: 423.59 ms/step | Epoch duration: 2405.80 ms/epoch --> loss: 3.6719 - val_loss: 4.1525\n",
      "Epoch 229/500 | Avg step duration: 429.42 ms/step | Epoch duration: 2417.08 ms/epoch --> loss: 3.6250 - val_loss: 4.2401\n",
      "Epoch 230/500 | Avg step duration: 423.88 ms/step | Epoch duration: 2404.93 ms/epoch --> loss: 3.5781 - val_loss: 4.1709\n",
      "Epoch 231/500 | Avg step duration: 429.94 ms/step | Epoch duration: 2418.93 ms/epoch --> loss: 3.6719 - val_loss: 4.1770\n",
      "Epoch 232/500 | Avg step duration: 446.07 ms/step | Epoch duration: 2475.31 ms/epoch --> loss: 3.6250 - val_loss: 4.2228\n",
      "Epoch 233/500 | Avg step duration: 430.79 ms/step | Epoch duration: 2425.61 ms/epoch --> loss: 3.6250 - val_loss: 4.1882\n",
      "Epoch 234/500 | Avg step duration: 428.38 ms/step | Epoch duration: 2425.81 ms/epoch --> loss: 3.6250 - val_loss: 4.2116\n",
      "Epoch 235/500 | Avg step duration: 429.20 ms/step | Epoch duration: 2430.20 ms/epoch --> loss: 3.5625 - val_loss: 4.1873\n",
      "Epoch 236/500 | Avg step duration: 425.31 ms/step | Epoch duration: 2424.01 ms/epoch --> loss: 3.6250 - val_loss: 4.1775\n",
      "Epoch 237/500 | Avg step duration: 423.33 ms/step | Epoch duration: 2404.14 ms/epoch --> loss: 3.6719 - val_loss: 4.1350\n",
      "Epoch 238/500 | Avg step duration: 423.46 ms/step | Epoch duration: 2403.60 ms/epoch --> loss: 3.5625 - val_loss: 4.1945\n",
      "Epoch 239/500 | Avg step duration: 429.61 ms/step | Epoch duration: 2421.86 ms/epoch --> loss: 3.6250 - val_loss: 4.1868\n",
      "Epoch 240/500 | Avg step duration: 424.37 ms/step | Epoch duration: 2431.93 ms/epoch --> loss: 3.5781 - val_loss: 4.2194\n",
      "Epoch 241/500 | Avg step duration: 424.46 ms/step | Epoch duration: 2406.54 ms/epoch --> loss: 3.5781 - val_loss: 4.1223\n",
      "Epoch 242/500 | Avg step duration: 425.58 ms/step | Epoch duration: 2428.25 ms/epoch --> loss: 3.5781 - val_loss: 4.1754\n",
      "Epoch 243/500 | Avg step duration: 424.18 ms/step | Epoch duration: 2420.79 ms/epoch --> loss: 3.6250 - val_loss: 4.1681\n",
      "Epoch 244/500 | Avg step duration: 424.19 ms/step | Epoch duration: 2405.25 ms/epoch --> loss: 3.5469 - val_loss: 4.1926\n",
      "Epoch 245/500 | Avg step duration: 424.13 ms/step | Epoch duration: 2404.59 ms/epoch --> loss: 3.5781 - val_loss: 4.2086\n",
      "Epoch 246/500 | Avg step duration: 423.83 ms/step | Epoch duration: 2404.97 ms/epoch --> loss: 3.5000 - val_loss: 4.1532\n",
      "Epoch 247/500 | Avg step duration: 428.82 ms/step | Epoch duration: 2419.28 ms/epoch --> loss: 3.5625 - val_loss: 4.1955\n",
      "Epoch 248/500 | Avg step duration: 424.64 ms/step | Epoch duration: 2444.10 ms/epoch --> loss: 3.5469 - val_loss: 4.1617\n",
      "Epoch 249/500 | Avg step duration: 424.31 ms/step | Epoch duration: 2404.80 ms/epoch --> loss: 3.6094 - val_loss: 4.1318\n",
      "Epoch 250/500 | Avg step duration: 425.28 ms/step | Epoch duration: 2410.16 ms/epoch --> loss: 3.6250 - val_loss: 4.1452\n",
      "Epoch 251/500 | Avg step duration: 424.01 ms/step | Epoch duration: 2426.90 ms/epoch --> loss: 3.4844 - val_loss: 4.1603\n",
      "Epoch 252/500 | Avg step duration: 425.42 ms/step | Epoch duration: 2409.14 ms/epoch --> loss: 3.5781 - val_loss: 4.1131\n",
      "Epoch 253/500 | Avg step duration: 424.21 ms/step | Epoch duration: 2405.44 ms/epoch --> loss: 3.5000 - val_loss: 4.2106\n",
      "Epoch 254/500 | Avg step duration: 428.44 ms/step | Epoch duration: 2410.59 ms/epoch --> loss: 3.5469 - val_loss: 4.1671\n",
      "Epoch 255/500 | Avg step duration: 429.49 ms/step | Epoch duration: 2420.85 ms/epoch --> loss: 3.5625 - val_loss: 4.1950\n",
      "Epoch 256/500 | Avg step duration: 424.31 ms/step | Epoch duration: 2410.91 ms/epoch --> loss: 3.6094 - val_loss: 4.1634\n",
      "Epoch 257/500 | Avg step duration: 424.16 ms/step | Epoch duration: 2406.87 ms/epoch --> loss: 3.5469 - val_loss: 4.1486\n",
      "Epoch 258/500 | Avg step duration: 423.73 ms/step | Epoch duration: 2409.34 ms/epoch --> loss: 3.5781 - val_loss: 4.1916\n",
      "Epoch 259/500 | Avg step duration: 424.91 ms/step | Epoch duration: 2421.96 ms/epoch --> loss: 3.5625 - val_loss: 4.1384\n",
      "Epoch 260/500 | Avg step duration: 427.42 ms/step | Epoch duration: 2415.31 ms/epoch --> loss: 3.5469 - val_loss: 4.1678\n",
      "Epoch 261/500 | Avg step duration: 424.09 ms/step | Epoch duration: 2419.18 ms/epoch --> loss: 3.4531 - val_loss: 4.1226\n",
      "Epoch 262/500 | Avg step duration: 424.21 ms/step | Epoch duration: 2407.26 ms/epoch --> loss: 3.5000 - val_loss: 4.1085\n",
      "Epoch 263/500 | Avg step duration: 427.00 ms/step | Epoch duration: 2410.88 ms/epoch --> loss: 3.3906 - val_loss: 4.1573\n",
      "Epoch 264/500 | Avg step duration: 424.18 ms/step | Epoch duration: 2419.48 ms/epoch --> loss: 3.4219 - val_loss: 4.0831\n",
      "Epoch 265/500 | Avg step duration: 424.09 ms/step | Epoch duration: 2420.76 ms/epoch --> loss: 3.4531 - val_loss: 4.1410\n",
      "Epoch 266/500 | Avg step duration: 424.43 ms/step | Epoch duration: 2410.13 ms/epoch --> loss: 3.5000 - val_loss: 4.1472\n",
      "Epoch 267/500 | Avg step duration: 423.74 ms/step | Epoch duration: 2406.00 ms/epoch --> loss: 3.5000 - val_loss: 4.1036\n",
      "Epoch 268/500 | Avg step duration: 427.86 ms/step | Epoch duration: 2416.01 ms/epoch --> loss: 3.4844 - val_loss: 4.0832\n",
      "Epoch 269/500 | Avg step duration: 423.95 ms/step | Epoch duration: 2422.09 ms/epoch --> loss: 3.5000 - val_loss: 4.0832\n",
      "Epoch 270/500 | Avg step duration: 423.91 ms/step | Epoch duration: 2406.37 ms/epoch --> loss: 3.5000 - val_loss: 4.1581\n",
      "Epoch 271/500 | Avg step duration: 422.49 ms/step | Epoch duration: 2418.90 ms/epoch --> loss: 3.5469 - val_loss: 4.1423\n",
      "Epoch 272/500 | Avg step duration: 423.56 ms/step | Epoch duration: 2412.10 ms/epoch --> loss: 3.4219 - val_loss: 4.1902\n",
      "Epoch 273/500 | Avg step duration: 425.59 ms/step | Epoch duration: 2411.33 ms/epoch --> loss: 3.5625 - val_loss: 4.0915\n",
      "Epoch 274/500 | Avg step duration: 429.08 ms/step | Epoch duration: 2422.15 ms/epoch --> loss: 3.3906 - val_loss: 4.1488\n",
      "Epoch 275/500 | Avg step duration: 426.92 ms/step | Epoch duration: 2403.75 ms/epoch --> loss: 3.3906 - val_loss: 4.1299\n",
      "Epoch 276/500 | Avg step duration: 423.02 ms/step | Epoch duration: 2405.42 ms/epoch --> loss: 3.4531 - val_loss: 4.1579\n",
      "Epoch 277/500 | Avg step duration: 428.21 ms/step | Epoch duration: 2510.05 ms/epoch --> loss: 3.4219 - val_loss: 4.1715\n",
      "Epoch 278/500 | Avg step duration: 458.89 ms/step | Epoch duration: 2490.43 ms/epoch --> loss: 3.3750 - val_loss: 4.1649\n",
      "Epoch 279/500 | Avg step duration: 423.44 ms/step | Epoch duration: 2395.97 ms/epoch --> loss: 3.4375 - val_loss: 4.1495\n",
      "Epoch 280/500 | Avg step duration: 425.91 ms/step | Epoch duration: 2408.29 ms/epoch --> loss: 3.3750 - val_loss: 4.1461\n",
      "Epoch 281/500 | Avg step duration: 422.36 ms/step | Epoch duration: 2408.35 ms/epoch --> loss: 3.3750 - val_loss: 4.1748\n",
      "Epoch 282/500 | Avg step duration: 423.68 ms/step | Epoch duration: 2404.27 ms/epoch --> loss: 3.4219 - val_loss: 4.1435\n",
      "Epoch 283/500 | Avg step duration: 425.23 ms/step | Epoch duration: 2413.88 ms/epoch --> loss: 3.5000 - val_loss: 4.1408\n",
      "Epoch 284/500 | Avg step duration: 423.89 ms/step | Epoch duration: 2406.56 ms/epoch --> loss: 3.4219 - val_loss: 4.0985\n",
      "Epoch 285/500 | Avg step duration: 426.55 ms/step | Epoch duration: 2414.10 ms/epoch --> loss: 3.3281 - val_loss: 4.1681\n",
      "Epoch 286/500 | Avg step duration: 423.53 ms/step | Epoch duration: 2416.95 ms/epoch --> loss: 3.2500 - val_loss: 4.0847\n",
      "Epoch 287/500 | Avg step duration: 423.88 ms/step | Epoch duration: 2405.71 ms/epoch --> loss: 3.3594 - val_loss: 4.1245\n",
      "Epoch 288/500 | Avg step duration: 422.79 ms/step | Epoch duration: 2408.83 ms/epoch --> loss: 3.3125 - val_loss: 4.0912\n",
      "Epoch 289/500 | Avg step duration: 426.54 ms/step | Epoch duration: 2411.75 ms/epoch --> loss: 3.3906 - val_loss: 4.1016\n",
      "Epoch 290/500 | Avg step duration: 424.39 ms/step | Epoch duration: 2406.23 ms/epoch --> loss: 3.3594 - val_loss: 4.0995\n",
      "Epoch 291/500 | Avg step duration: 422.85 ms/step | Epoch duration: 2418.44 ms/epoch --> loss: 3.3125 - val_loss: 4.1262\n",
      "Epoch 292/500 | Avg step duration: 424.19 ms/step | Epoch duration: 2406.74 ms/epoch --> loss: 3.2969 - val_loss: 4.1258\n",
      "Epoch 293/500 | Avg step duration: 423.37 ms/step | Epoch duration: 2404.71 ms/epoch --> loss: 3.3750 - val_loss: 4.1286\n",
      "Epoch 294/500 | Avg step duration: 423.84 ms/step | Epoch duration: 2402.36 ms/epoch --> loss: 3.3750 - val_loss: 4.0506\n",
      "Epoch 295/500 | Avg step duration: 429.94 ms/step | Epoch duration: 2423.38 ms/epoch --> loss: 3.3281 - val_loss: 4.1512\n",
      "Epoch 296/500 | Avg step duration: 430.70 ms/step | Epoch duration: 2450.73 ms/epoch --> loss: 3.3281 - val_loss: 4.1579\n",
      "Epoch 297/500 | Avg step duration: 424.80 ms/step | Epoch duration: 2408.66 ms/epoch --> loss: 3.3906 - val_loss: 4.1034\n",
      "Epoch 298/500 | Avg step duration: 423.90 ms/step | Epoch duration: 2406.48 ms/epoch --> loss: 3.3281 - val_loss: 4.1270\n",
      "Epoch 299/500 | Avg step duration: 424.41 ms/step | Epoch duration: 2418.99 ms/epoch --> loss: 3.2500 - val_loss: 4.1671\n",
      "Epoch 300/500 | Avg step duration: 423.85 ms/step | Epoch duration: 2405.46 ms/epoch --> loss: 3.2969 - val_loss: 4.0820\n",
      "Epoch 301/500 | Avg step duration: 426.90 ms/step | Epoch duration: 2417.05 ms/epoch --> loss: 3.3281 - val_loss: 4.0999\n",
      "Epoch 302/500 | Avg step duration: 423.51 ms/step | Epoch duration: 2402.45 ms/epoch --> loss: 3.3594 - val_loss: 4.0759\n",
      "Epoch 303/500 | Avg step duration: 422.90 ms/step | Epoch duration: 2408.51 ms/epoch --> loss: 3.3125 - val_loss: 4.1321\n",
      "Epoch 304/500 | Avg step duration: 423.03 ms/step | Epoch duration: 2406.68 ms/epoch --> loss: 3.3281 - val_loss: 4.1449\n",
      "Epoch 305/500 | Avg step duration: 423.95 ms/step | Epoch duration: 2406.13 ms/epoch --> loss: 3.3125 - val_loss: 4.1078\n",
      "Epoch 306/500 | Avg step duration: 422.29 ms/step | Epoch duration: 2410.81 ms/epoch --> loss: 3.2344 - val_loss: 4.1257\n",
      "Epoch 307/500 | Avg step duration: 425.86 ms/step | Epoch duration: 2420.60 ms/epoch --> loss: 3.2969 - val_loss: 4.0501\n",
      "Epoch 308/500 | Avg step duration: 426.29 ms/step | Epoch duration: 2412.06 ms/epoch --> loss: 3.2500 - val_loss: 4.1202\n",
      "Epoch 309/500 | Avg step duration: 424.60 ms/step | Epoch duration: 2423.08 ms/epoch --> loss: 3.2656 - val_loss: 4.0645\n",
      "Epoch 310/500 | Avg step duration: 423.88 ms/step | Epoch duration: 2406.05 ms/epoch --> loss: 3.4219 - val_loss: 4.1335\n",
      "Epoch 311/500 | Avg step duration: 423.38 ms/step | Epoch duration: 2414.06 ms/epoch --> loss: 3.3750 - val_loss: 4.1311\n",
      "Epoch 312/500 | Avg step duration: 423.45 ms/step | Epoch duration: 2404.91 ms/epoch --> loss: 3.2500 - val_loss: 4.1743\n",
      "Epoch 313/500 | Avg step duration: 429.90 ms/step | Epoch duration: 2427.26 ms/epoch --> loss: 3.2969 - val_loss: 4.1255\n",
      "Epoch 314/500 | Avg step duration: 423.36 ms/step | Epoch duration: 2405.32 ms/epoch --> loss: 3.1719 - val_loss: 4.0968\n",
      "Epoch 315/500 | Avg step duration: 424.47 ms/step | Epoch duration: 2408.50 ms/epoch --> loss: 3.2500 - val_loss: 4.0518\n",
      "Epoch 316/500 | Avg step duration: 422.80 ms/step | Epoch duration: 2402.16 ms/epoch --> loss: 3.2344 - val_loss: 4.0776\n",
      "Epoch 317/500 | Avg step duration: 423.39 ms/step | Epoch duration: 2403.12 ms/epoch --> loss: 3.3281 - val_loss: 4.1258\n",
      "Epoch 318/500 | Avg step duration: 423.50 ms/step | Epoch duration: 2404.58 ms/epoch --> loss: 3.2344 - val_loss: 4.0968\n",
      "Epoch 319/500 | Avg step duration: 429.85 ms/step | Epoch duration: 2428.61 ms/epoch --> loss: 3.2656 - val_loss: 4.1067\n",
      "Epoch 320/500 | Avg step duration: 423.45 ms/step | Epoch duration: 2405.19 ms/epoch --> loss: 3.1875 - val_loss: 4.1685\n",
      "Epoch 321/500 | Avg step duration: 423.51 ms/step | Epoch duration: 2420.04 ms/epoch --> loss: 3.2500 - val_loss: 4.1702\n",
      "Epoch 322/500 | Avg step duration: 424.00 ms/step | Epoch duration: 2406.44 ms/epoch --> loss: 3.2500 - val_loss: 4.1377\n",
      "Epoch 323/500 | Avg step duration: 423.97 ms/step | Epoch duration: 2406.03 ms/epoch --> loss: 3.2656 - val_loss: 4.0819\n",
      "Epoch 324/500 | Avg step duration: 423.66 ms/step | Epoch duration: 2431.41 ms/epoch --> loss: 3.2500 - val_loss: 4.0644\n",
      "Epoch 325/500 | Avg step duration: 423.91 ms/step | Epoch duration: 2402.86 ms/epoch --> loss: 3.3281 - val_loss: 4.0883\n",
      "Epoch 326/500 | Avg step duration: 423.21 ms/step | Epoch duration: 2403.10 ms/epoch --> loss: 3.2500 - val_loss: 4.0724\n",
      "Epoch 327/500 | Avg step duration: 423.71 ms/step | Epoch duration: 2404.32 ms/epoch --> loss: 3.1250 - val_loss: 4.1221\n",
      "Epoch 328/500 | Avg step duration: 430.11 ms/step | Epoch duration: 2423.09 ms/epoch --> loss: 3.2031 - val_loss: 4.0878\n",
      "Epoch 329/500 | Avg step duration: 422.41 ms/step | Epoch duration: 2412.29 ms/epoch --> loss: 3.1719 - val_loss: 4.1090\n",
      "Epoch 330/500 | Avg step duration: 424.63 ms/step | Epoch duration: 2423.78 ms/epoch --> loss: 3.1250 - val_loss: 4.0932\n",
      "Epoch 331/500 | Avg step duration: 422.88 ms/step | Epoch duration: 2405.06 ms/epoch --> loss: 3.2031 - val_loss: 4.1196\n",
      "Epoch 332/500 | Avg step duration: 423.58 ms/step | Epoch duration: 2404.84 ms/epoch --> loss: 3.1719 - val_loss: 4.0936\n",
      "Epoch 333/500 | Avg step duration: 427.13 ms/step | Epoch duration: 2415.44 ms/epoch --> loss: 3.1875 - val_loss: 4.1138\n",
      "Epoch 334/500 | Avg step duration: 423.53 ms/step | Epoch duration: 2415.82 ms/epoch --> loss: 3.2344 - val_loss: 4.1126\n",
      "Epoch 335/500 | Avg step duration: 423.24 ms/step | Epoch duration: 2404.50 ms/epoch --> loss: 3.1719 - val_loss: 4.0572\n",
      "Epoch 336/500 | Avg step duration: 423.05 ms/step | Epoch duration: 2403.39 ms/epoch --> loss: 3.0156 - val_loss: 4.1491\n",
      "Epoch 337/500 | Avg step duration: 430.87 ms/step | Epoch duration: 2437.35 ms/epoch --> loss: 3.2031 - val_loss: 4.1201\n",
      "Epoch 338/500 | Avg step duration: 423.57 ms/step | Epoch duration: 2403.49 ms/epoch --> loss: 3.1250 - val_loss: 4.1206\n",
      "Epoch 339/500 | Avg step duration: 423.28 ms/step | Epoch duration: 2417.28 ms/epoch --> loss: 3.1406 - val_loss: 4.0853\n",
      "Epoch 340/500 | Avg step duration: 423.94 ms/step | Epoch duration: 2407.93 ms/epoch --> loss: 3.1250 - val_loss: 4.1129\n",
      "Epoch 341/500 | Avg step duration: 428.13 ms/step | Epoch duration: 2418.27 ms/epoch --> loss: 3.1250 - val_loss: 4.0722\n",
      "Epoch 342/500 | Avg step duration: 422.98 ms/step | Epoch duration: 2417.05 ms/epoch --> loss: 3.0781 - val_loss: 4.1133\n",
      "Epoch 343/500 | Avg step duration: 428.65 ms/step | Epoch duration: 2419.16 ms/epoch --> loss: 3.0469 - val_loss: 4.0814\n",
      "Epoch 344/500 | Avg step duration: 422.70 ms/step | Epoch duration: 2402.94 ms/epoch --> loss: 3.0625 - val_loss: 4.1328\n",
      "Epoch 345/500 | Avg step duration: 422.52 ms/step | Epoch duration: 2401.40 ms/epoch --> loss: 3.0469 - val_loss: 4.1126\n",
      "Epoch 346/500 | Avg step duration: 428.42 ms/step | Epoch duration: 2417.97 ms/epoch --> loss: 3.1094 - val_loss: 4.0542\n",
      "Epoch 347/500 | Avg step duration: 423.47 ms/step | Epoch duration: 2414.22 ms/epoch --> loss: 3.2031 - val_loss: 4.1214\n",
      "Epoch 348/500 | Avg step duration: 429.31 ms/step | Epoch duration: 2419.91 ms/epoch --> loss: 3.1094 - val_loss: 4.1281\n",
      "Epoch 349/500 | Avg step duration: 423.09 ms/step | Epoch duration: 2403.28 ms/epoch --> loss: 3.1094 - val_loss: 4.0487\n",
      "Epoch 350/500 | Avg step duration: 423.76 ms/step | Epoch duration: 2399.81 ms/epoch --> loss: 3.0469 - val_loss: 4.1267\n",
      "Epoch 351/500 | Avg step duration: 428.38 ms/step | Epoch duration: 2417.76 ms/epoch --> loss: 3.1719 - val_loss: 4.0506\n",
      "Epoch 352/500 | Avg step duration: 423.03 ms/step | Epoch duration: 2432.18 ms/epoch --> loss: 3.1094 - val_loss: 4.1140\n",
      "Epoch 353/500 | Avg step duration: 424.33 ms/step | Epoch duration: 2405.58 ms/epoch --> loss: 3.1719 - val_loss: 4.1033\n",
      "Epoch 354/500 | Avg step duration: 426.46 ms/step | Epoch duration: 2413.09 ms/epoch --> loss: 3.0469 - val_loss: 4.1162\n",
      "Epoch 355/500 | Avg step duration: 423.90 ms/step | Epoch duration: 2416.73 ms/epoch --> loss: 3.1250 - val_loss: 4.0258\n",
      "Epoch 356/500 | Avg step duration: 424.46 ms/step | Epoch duration: 2406.23 ms/epoch --> loss: 3.0469 - val_loss: 4.0883\n",
      "Epoch 357/500 | Avg step duration: 423.91 ms/step | Epoch duration: 2414.72 ms/epoch --> loss: 3.0781 - val_loss: 4.1452\n",
      "Epoch 358/500 | Avg step duration: 423.75 ms/step | Epoch duration: 2401.06 ms/epoch --> loss: 2.9844 - val_loss: 4.0822\n",
      "Epoch 359/500 | Avg step duration: 423.48 ms/step | Epoch duration: 2404.49 ms/epoch --> loss: 3.0781 - val_loss: 4.0990\n",
      "Epoch 360/500 | Avg step duration: 429.32 ms/step | Epoch duration: 2436.32 ms/epoch --> loss: 3.0000 - val_loss: 4.1461\n",
      "Epoch 361/500 | Avg step duration: 424.36 ms/step | Epoch duration: 2407.87 ms/epoch --> loss: 3.1094 - val_loss: 4.1201\n",
      "Epoch 362/500 | Avg step duration: 423.36 ms/step | Epoch duration: 2411.99 ms/epoch --> loss: 3.1094 - val_loss: 4.0627\n",
      "Epoch 363/500 | Avg step duration: 424.43 ms/step | Epoch duration: 2406.50 ms/epoch --> loss: 3.0469 - val_loss: 4.1248\n",
      "Epoch 364/500 | Avg step duration: 425.63 ms/step | Epoch duration: 2414.32 ms/epoch --> loss: 3.1094 - val_loss: 4.0956\n",
      "Epoch 365/500 | Avg step duration: 423.35 ms/step | Epoch duration: 2417.41 ms/epoch --> loss: 3.0469 - val_loss: 4.1072\n",
      "Epoch 366/500 | Avg step duration: 426.58 ms/step | Epoch duration: 2407.08 ms/epoch --> loss: 3.1250 - val_loss: 4.1024\n",
      "Epoch 367/500 | Avg step duration: 427.18 ms/step | Epoch duration: 2408.73 ms/epoch --> loss: 3.0469 - val_loss: 4.1406\n",
      "Epoch 368/500 | Avg step duration: 423.68 ms/step | Epoch duration: 2404.37 ms/epoch --> loss: 3.0469 - val_loss: 4.1269\n",
      "Epoch 369/500 | Avg step duration: 424.25 ms/step | Epoch duration: 2406.49 ms/epoch --> loss: 2.9375 - val_loss: 4.0831\n",
      "Epoch 370/500 | Avg step duration: 462.07 ms/step | Epoch duration: 2525.66 ms/epoch --> loss: 3.0469 - val_loss: 4.1053\n",
      "Epoch 371/500 | Avg step duration: 423.15 ms/step | Epoch duration: 2413.61 ms/epoch --> loss: 3.0781 - val_loss: 4.1315\n",
      "Epoch 372/500 | Avg step duration: 428.54 ms/step | Epoch duration: 2417.00 ms/epoch --> loss: 3.0781 - val_loss: 4.0808\n",
      "Epoch 373/500 | Avg step duration: 422.72 ms/step | Epoch duration: 2408.60 ms/epoch --> loss: 2.9531 - val_loss: 4.0737\n",
      "Epoch 374/500 | Avg step duration: 423.66 ms/step | Epoch duration: 2407.00 ms/epoch --> loss: 2.9531 - val_loss: 4.1250\n",
      "Epoch 375/500 | Avg step duration: 423.41 ms/step | Epoch duration: 2413.15 ms/epoch --> loss: 3.1250 - val_loss: 4.0769\n",
      "Epoch 376/500 | Avg step duration: 422.95 ms/step | Epoch duration: 2406.11 ms/epoch --> loss: 2.9219 - val_loss: 4.1554\n",
      "Epoch 377/500 | Avg step duration: 428.36 ms/step | Epoch duration: 2438.42 ms/epoch --> loss: 2.9844 - val_loss: 4.1000\n",
      "Epoch 378/500 | Avg step duration: 423.41 ms/step | Epoch duration: 2408.08 ms/epoch --> loss: 2.8750 - val_loss: 4.1189\n",
      "Epoch 379/500 | Avg step duration: 424.25 ms/step | Epoch duration: 2405.47 ms/epoch --> loss: 3.0000 - val_loss: 4.1175\n",
      "Epoch 380/500 | Avg step duration: 422.93 ms/step | Epoch duration: 2406.31 ms/epoch --> loss: 2.9531 - val_loss: 4.1140\n",
      "Epoch 381/500 | Avg step duration: 422.53 ms/step | Epoch duration: 2400.68 ms/epoch --> loss: 2.9531 - val_loss: 4.1082\n",
      "Epoch 382/500 | Avg step duration: 428.65 ms/step | Epoch duration: 2418.79 ms/epoch --> loss: 2.9531 - val_loss: 4.1174\n",
      "Epoch 383/500 | Avg step duration: 423.07 ms/step | Epoch duration: 2435.14 ms/epoch --> loss: 2.9531 - val_loss: 4.0594\n",
      "Epoch 384/500 | Avg step duration: 424.21 ms/step | Epoch duration: 2405.76 ms/epoch --> loss: 2.8750 - val_loss: 4.0922\n",
      "Epoch 385/500 | Avg step duration: 423.49 ms/step | Epoch duration: 2404.41 ms/epoch --> loss: 2.9531 - val_loss: 4.0980\n",
      "Epoch 386/500 | Avg step duration: 423.34 ms/step | Epoch duration: 2405.95 ms/epoch --> loss: 2.8281 - val_loss: 4.1624\n",
      "Epoch 387/500 | Avg step duration: 433.92 ms/step | Epoch duration: 2435.49 ms/epoch --> loss: 2.9219 - val_loss: 4.1287\n",
      "Epoch 388/500 | Avg step duration: 422.62 ms/step | Epoch duration: 2411.57 ms/epoch --> loss: 2.9219 - val_loss: 4.0956\n",
      "Epoch 389/500 | Avg step duration: 424.37 ms/step | Epoch duration: 2423.27 ms/epoch --> loss: 2.8750 - val_loss: 4.1335\n",
      "Epoch 390/500 | Avg step duration: 424.90 ms/step | Epoch duration: 2407.70 ms/epoch --> loss: 2.8906 - val_loss: 4.1245\n",
      "Epoch 391/500 | Avg step duration: 422.82 ms/step | Epoch duration: 2410.97 ms/epoch --> loss: 2.8750 - val_loss: 4.0448\n",
      "Epoch 392/500 | Avg step duration: 423.47 ms/step | Epoch duration: 2404.41 ms/epoch --> loss: 2.9531 - val_loss: 4.0520\n",
      "Epoch 393/500 | Avg step duration: 423.54 ms/step | Epoch duration: 2416.81 ms/epoch --> loss: 2.9844 - val_loss: 4.1411\n",
      "Epoch 394/500 | Avg step duration: 423.84 ms/step | Epoch duration: 2405.17 ms/epoch --> loss: 2.9375 - val_loss: 4.1493\n",
      "Epoch 395/500 | Avg step duration: 422.28 ms/step | Epoch duration: 2415.84 ms/epoch --> loss: 2.8281 - val_loss: 4.1410\n",
      "Epoch 396/500 | Avg step duration: 422.80 ms/step | Epoch duration: 2407.24 ms/epoch --> loss: 2.9219 - val_loss: 4.1799\n",
      "Epoch 397/500 | Avg step duration: 424.27 ms/step | Epoch duration: 2405.95 ms/epoch --> loss: 2.8281 - val_loss: 4.0472\n",
      "Epoch 398/500 | Avg step duration: 423.30 ms/step | Epoch duration: 2406.79 ms/epoch --> loss: 2.9219 - val_loss: 4.0922\n",
      "Epoch 399/500 | Avg step duration: 424.44 ms/step | Epoch duration: 2402.91 ms/epoch --> loss: 2.8906 - val_loss: 4.0472\n",
      "Epoch 400/500 | Avg step duration: 423.64 ms/step | Epoch duration: 2410.99 ms/epoch --> loss: 2.9531 - val_loss: 4.0900\n",
      "Epoch 401/500 | Avg step duration: 425.92 ms/step | Epoch duration: 2411.83 ms/epoch --> loss: 2.7500 - val_loss: 4.1028\n",
      "Epoch 402/500 | Avg step duration: 425.11 ms/step | Epoch duration: 2408.70 ms/epoch --> loss: 2.8125 - val_loss: 4.1382\n",
      "Epoch 403/500 | Avg step duration: 423.92 ms/step | Epoch duration: 2414.41 ms/epoch --> loss: 2.8281 - val_loss: 4.1325\n",
      "Epoch 404/500 | Avg step duration: 424.16 ms/step | Epoch duration: 2406.63 ms/epoch --> loss: 2.9219 - val_loss: 4.1157\n",
      "Epoch 405/500 | Avg step duration: 422.37 ms/step | Epoch duration: 2414.68 ms/epoch --> loss: 2.9375 - val_loss: 4.1748\n",
      "Epoch 406/500 | Avg step duration: 422.66 ms/step | Epoch duration: 2402.83 ms/epoch --> loss: 2.8594 - val_loss: 4.0963\n",
      "Epoch 407/500 | Avg step duration: 427.55 ms/step | Epoch duration: 2423.37 ms/epoch --> loss: 2.7656 - val_loss: 4.0776\n",
      "Epoch 408/500 | Avg step duration: 423.65 ms/step | Epoch duration: 2406.67 ms/epoch --> loss: 2.7969 - val_loss: 4.1630\n",
      "Epoch 409/500 | Avg step duration: 424.63 ms/step | Epoch duration: 2409.23 ms/epoch --> loss: 2.8594 - val_loss: 4.0895\n",
      "Epoch 410/500 | Avg step duration: 424.95 ms/step | Epoch duration: 2414.98 ms/epoch --> loss: 2.9375 - val_loss: 4.1600\n",
      "Epoch 411/500 | Avg step duration: 423.59 ms/step | Epoch duration: 2401.89 ms/epoch --> loss: 2.8750 - val_loss: 4.1326\n",
      "Epoch 412/500 | Avg step duration: 423.55 ms/step | Epoch duration: 2423.84 ms/epoch --> loss: 2.7969 - val_loss: 4.0788\n",
      "Epoch 413/500 | Avg step duration: 422.77 ms/step | Epoch duration: 2393.50 ms/epoch --> loss: 2.7500 - val_loss: 4.1439\n",
      "Epoch 414/500 | Avg step duration: 429.59 ms/step | Epoch duration: 2414.92 ms/epoch --> loss: 2.7969 - val_loss: 4.0831\n",
      "Epoch 415/500 | Avg step duration: 423.38 ms/step | Epoch duration: 2414.43 ms/epoch --> loss: 2.7969 - val_loss: 4.1646\n",
      "Epoch 416/500 | Avg step duration: 425.52 ms/step | Epoch duration: 2462.00 ms/epoch --> loss: 2.8281 - val_loss: 4.1554\n",
      "Epoch 417/500 | Avg step duration: 424.91 ms/step | Epoch duration: 2407.98 ms/epoch --> loss: 2.7969 - val_loss: 4.1690\n",
      "Epoch 418/500 | Avg step duration: 431.52 ms/step | Epoch duration: 2441.51 ms/epoch --> loss: 2.7031 - val_loss: 4.1535\n",
      "Epoch 419/500 | Avg step duration: 423.70 ms/step | Epoch duration: 2403.67 ms/epoch --> loss: 2.8750 - val_loss: 4.0978\n",
      "Epoch 420/500 | Avg step duration: 423.18 ms/step | Epoch duration: 2405.60 ms/epoch --> loss: 2.7500 - val_loss: 4.1890\n",
      "Epoch 421/500 | Avg step duration: 422.97 ms/step | Epoch duration: 2420.68 ms/epoch --> loss: 2.6875 - val_loss: 4.1056\n",
      "Epoch 422/500 | Avg step duration: 423.02 ms/step | Epoch duration: 2400.63 ms/epoch --> loss: 2.7969 - val_loss: 4.1603\n",
      "Epoch 423/500 | Avg step duration: 423.76 ms/step | Epoch duration: 2429.20 ms/epoch --> loss: 2.6875 - val_loss: 4.1462\n",
      "Epoch 424/500 | Avg step duration: 423.85 ms/step | Epoch duration: 2404.20 ms/epoch --> loss: 2.6719 - val_loss: 4.1941\n",
      "Epoch 425/500 | Avg step duration: 422.04 ms/step | Epoch duration: 2398.44 ms/epoch --> loss: 2.6875 - val_loss: 4.1323\n",
      "Epoch 426/500 | Avg step duration: 423.10 ms/step | Epoch duration: 2402.87 ms/epoch --> loss: 2.6875 - val_loss: 4.1880\n",
      "Epoch 427/500 | Avg step duration: 429.71 ms/step | Epoch duration: 2421.94 ms/epoch --> loss: 2.6562 - val_loss: 4.1955\n",
      "Epoch 428/500 | Avg step duration: 423.29 ms/step | Epoch duration: 2414.76 ms/epoch --> loss: 2.7969 - val_loss: 4.1192\n",
      "Epoch 429/500 | Avg step duration: 421.83 ms/step | Epoch duration: 2403.59 ms/epoch --> loss: 2.6250 - val_loss: 4.1642\n",
      "Epoch 430/500 | Avg step duration: 420.26 ms/step | Epoch duration: 2407.51 ms/epoch --> loss: 2.7500 - val_loss: 4.1432\n",
      "Epoch 431/500 | Avg step duration: 423.54 ms/step | Epoch duration: 2403.32 ms/epoch --> loss: 2.6250 - val_loss: 4.1819\n",
      "Epoch 432/500 | Avg step duration: 422.05 ms/step | Epoch duration: 2391.35 ms/epoch --> loss: 2.7031 - val_loss: 4.0802\n",
      "Epoch 433/500 | Avg step duration: 426.55 ms/step | Epoch duration: 2431.48 ms/epoch --> loss: 2.7656 - val_loss: 4.1323\n",
      "Epoch 434/500 | Avg step duration: 423.54 ms/step | Epoch duration: 2403.22 ms/epoch --> loss: 2.5625 - val_loss: 4.1036\n",
      "Epoch 435/500 | Avg step duration: 427.31 ms/step | Epoch duration: 2528.73 ms/epoch --> loss: 2.7031 - val_loss: 4.1793\n",
      "Epoch 436/500 | Avg step duration: 422.76 ms/step | Epoch duration: 2406.90 ms/epoch --> loss: 2.6719 - val_loss: 4.0921\n",
      "Epoch 437/500 | Avg step duration: 424.28 ms/step | Epoch duration: 2402.23 ms/epoch --> loss: 2.7031 - val_loss: 4.1355\n",
      "Epoch 438/500 | Avg step duration: 423.54 ms/step | Epoch duration: 2402.63 ms/epoch --> loss: 2.6875 - val_loss: 4.1970\n",
      "Epoch 439/500 | Avg step duration: 422.79 ms/step | Epoch duration: 2403.61 ms/epoch --> loss: 2.6875 - val_loss: 4.1218\n",
      "Epoch 440/500 | Avg step duration: 429.51 ms/step | Epoch duration: 2443.16 ms/epoch --> loss: 2.6719 - val_loss: 4.1078\n",
      "Epoch 441/500 | Avg step duration: 423.18 ms/step | Epoch duration: 2408.38 ms/epoch --> loss: 2.6562 - val_loss: 4.2072\n",
      "Epoch 442/500 | Avg step duration: 424.16 ms/step | Epoch duration: 2406.48 ms/epoch --> loss: 2.6094 - val_loss: 4.2033\n",
      "Epoch 443/500 | Avg step duration: 425.57 ms/step | Epoch duration: 2411.17 ms/epoch --> loss: 2.6406 - val_loss: 4.1585\n",
      "Epoch 444/500 | Avg step duration: 425.27 ms/step | Epoch duration: 2413.60 ms/epoch --> loss: 2.6719 - val_loss: 4.1349\n",
      "Epoch 445/500 | Avg step duration: 424.33 ms/step | Epoch duration: 2407.61 ms/epoch --> loss: 2.5781 - val_loss: 4.1850\n",
      "Epoch 446/500 | Avg step duration: 432.30 ms/step | Epoch duration: 2430.67 ms/epoch --> loss: 2.5156 - val_loss: 4.0620\n",
      "Epoch 447/500 | Avg step duration: 422.92 ms/step | Epoch duration: 2401.70 ms/epoch --> loss: 2.5469 - val_loss: 4.1671\n",
      "Epoch 448/500 | Avg step duration: 422.86 ms/step | Epoch duration: 2406.07 ms/epoch --> loss: 2.6250 - val_loss: 4.2254\n",
      "Epoch 449/500 | Avg step duration: 423.08 ms/step | Epoch duration: 2411.70 ms/epoch --> loss: 2.5781 - val_loss: 4.1629\n",
      "Epoch 450/500 | Avg step duration: 423.30 ms/step | Epoch duration: 2404.57 ms/epoch --> loss: 2.6562 - val_loss: 4.1525\n",
      "Epoch 451/500 | Avg step duration: 423.80 ms/step | Epoch duration: 2436.12 ms/epoch --> loss: 2.5781 - val_loss: 4.1128\n",
      "Epoch 452/500 | Avg step duration: 424.41 ms/step | Epoch duration: 2406.80 ms/epoch --> loss: 2.4375 - val_loss: 4.2145\n",
      "Epoch 453/500 | Avg step duration: 425.21 ms/step | Epoch duration: 2414.31 ms/epoch --> loss: 2.5781 - val_loss: 4.1636\n",
      "Epoch 454/500 | Avg step duration: 423.39 ms/step | Epoch duration: 2404.81 ms/epoch --> loss: 2.4375 - val_loss: 4.1957\n",
      "Epoch 455/500 | Avg step duration: 424.48 ms/step | Epoch duration: 2406.08 ms/epoch --> loss: 2.6406 - val_loss: 4.1861\n",
      "Epoch 456/500 | Avg step duration: 423.62 ms/step | Epoch duration: 2432.83 ms/epoch --> loss: 2.5625 - val_loss: 4.1912\n",
      "Epoch 457/500 | Avg step duration: 426.57 ms/step | Epoch duration: 2411.69 ms/epoch --> loss: 2.5156 - val_loss: 4.1466\n",
      "Epoch 458/500 | Avg step duration: 423.54 ms/step | Epoch duration: 2403.19 ms/epoch --> loss: 2.5781 - val_loss: 4.2449\n",
      "Epoch 459/500 | Avg step duration: 423.50 ms/step | Epoch duration: 2420.21 ms/epoch --> loss: 2.5312 - val_loss: 4.0854\n",
      "Epoch 460/500 | Avg step duration: 424.91 ms/step | Epoch duration: 2408.48 ms/epoch --> loss: 2.5781 - val_loss: 4.1724\n",
      "Epoch 461/500 | Avg step duration: 423.49 ms/step | Epoch duration: 2411.20 ms/epoch --> loss: 2.3594 - val_loss: 4.1979\n",
      "Epoch 462/500 | Avg step duration: 429.41 ms/step | Epoch duration: 2416.51 ms/epoch --> loss: 2.4531 - val_loss: 4.2186\n",
      "Epoch 463/500 | Avg step duration: 425.68 ms/step | Epoch duration: 2409.71 ms/epoch --> loss: 2.4531 - val_loss: 4.1552\n",
      "Epoch 464/500 | Avg step duration: 423.67 ms/step | Epoch duration: 2416.71 ms/epoch --> loss: 2.4062 - val_loss: 4.1505\n",
      "Epoch 465/500 | Avg step duration: 425.74 ms/step | Epoch duration: 2406.70 ms/epoch --> loss: 2.5469 - val_loss: 4.1461\n",
      "Epoch 466/500 | Avg step duration: 423.09 ms/step | Epoch duration: 2414.45 ms/epoch --> loss: 2.5000 - val_loss: 4.2782\n",
      "Epoch 467/500 | Avg step duration: 444.81 ms/step | Epoch duration: 2495.75 ms/epoch --> loss: 2.4375 - val_loss: 4.1882\n",
      "Epoch 468/500 | Avg step duration: 438.48 ms/step | Epoch duration: 2467.12 ms/epoch --> loss: 2.3594 - val_loss: 4.2050\n",
      "Epoch 469/500 | Avg step duration: 429.02 ms/step | Epoch duration: 2425.66 ms/epoch --> loss: 2.3594 - val_loss: 4.1868\n",
      "Epoch 470/500 | Avg step duration: 430.36 ms/step | Epoch duration: 2442.38 ms/epoch --> loss: 2.4531 - val_loss: 4.2439\n",
      "Epoch 471/500 | Avg step duration: 432.88 ms/step | Epoch duration: 2466.62 ms/epoch --> loss: 2.6406 - val_loss: 4.2052\n",
      "Epoch 472/500 | Avg step duration: 431.14 ms/step | Epoch duration: 2428.87 ms/epoch --> loss: 2.3125 - val_loss: 4.2490\n",
      "Epoch 473/500 | Avg step duration: 424.01 ms/step | Epoch duration: 2405.20 ms/epoch --> loss: 2.5156 - val_loss: 4.1960\n",
      "Epoch 474/500 | Avg step duration: 422.46 ms/step | Epoch duration: 2415.18 ms/epoch --> loss: 2.3906 - val_loss: 4.1940\n",
      "Epoch 475/500 | Avg step duration: 425.81 ms/step | Epoch duration: 2410.75 ms/epoch --> loss: 2.3906 - val_loss: 4.2108\n",
      "Epoch 476/500 | Avg step duration: 431.26 ms/step | Epoch duration: 2450.04 ms/epoch --> loss: 2.3594 - val_loss: 4.1158\n",
      "Epoch 477/500 | Avg step duration: 423.71 ms/step | Epoch duration: 2413.24 ms/epoch --> loss: 2.3906 - val_loss: 4.2261\n",
      "Epoch 478/500 | Avg step duration: 425.06 ms/step | Epoch duration: 2407.46 ms/epoch --> loss: 2.3281 - val_loss: 4.3025\n",
      "Epoch 479/500 | Avg step duration: 427.56 ms/step | Epoch duration: 2416.20 ms/epoch --> loss: 2.4375 - val_loss: 4.2570\n",
      "Epoch 480/500 | Avg step duration: 422.69 ms/step | Epoch duration: 2403.16 ms/epoch --> loss: 2.4375 - val_loss: 4.1812\n",
      "Epoch 481/500 | Avg step duration: 429.25 ms/step | Epoch duration: 2421.44 ms/epoch --> loss: 2.3281 - val_loss: 4.1843\n",
      "Epoch 482/500 | Avg step duration: 423.65 ms/step | Epoch duration: 2408.33 ms/epoch --> loss: 2.4219 - val_loss: 4.2123\n",
      "Epoch 483/500 | Avg step duration: 424.02 ms/step | Epoch duration: 2404.83 ms/epoch --> loss: 2.3281 - val_loss: 4.2242\n",
      "Epoch 484/500 | Avg step duration: 423.38 ms/step | Epoch duration: 2403.16 ms/epoch --> loss: 2.3281 - val_loss: 4.1187\n",
      "Epoch 485/500 | Avg step duration: 424.31 ms/step | Epoch duration: 2407.27 ms/epoch --> loss: 2.4375 - val_loss: 4.2257\n",
      "Epoch 486/500 | Avg step duration: 430.31 ms/step | Epoch duration: 2423.85 ms/epoch --> loss: 2.3750 - val_loss: 4.2293\n",
      "Epoch 487/500 | Avg step duration: 423.54 ms/step | Epoch duration: 2414.33 ms/epoch --> loss: 2.4531 - val_loss: 4.1909\n",
      "Epoch 488/500 | Avg step duration: 424.27 ms/step | Epoch duration: 2405.81 ms/epoch --> loss: 2.3906 - val_loss: 4.2498\n",
      "Epoch 489/500 | Avg step duration: 423.61 ms/step | Epoch duration: 2406.91 ms/epoch --> loss: 2.4219 - val_loss: 4.2668\n",
      "Epoch 490/500 | Avg step duration: 424.50 ms/step | Epoch duration: 2407.07 ms/epoch --> loss: 2.2969 - val_loss: 4.2503\n",
      "Epoch 491/500 | Avg step duration: 426.91 ms/step | Epoch duration: 2413.77 ms/epoch --> loss: 2.3125 - val_loss: 4.2182\n",
      "Epoch 492/500 | Avg step duration: 423.62 ms/step | Epoch duration: 2415.08 ms/epoch --> loss: 2.3281 - val_loss: 4.2041\n",
      "Epoch 493/500 | Avg step duration: 424.11 ms/step | Epoch duration: 2405.28 ms/epoch --> loss: 2.3594 - val_loss: 4.2879\n",
      "Epoch 494/500 | Avg step duration: 432.09 ms/step | Epoch duration: 2430.36 ms/epoch --> loss: 2.2969 - val_loss: 4.1934\n",
      "Epoch 495/500 | Avg step duration: 423.44 ms/step | Epoch duration: 2406.04 ms/epoch --> loss: 2.2969 - val_loss: 4.2655\n",
      "Epoch 496/500 | Avg step duration: 425.09 ms/step | Epoch duration: 2408.80 ms/epoch --> loss: 2.2969 - val_loss: 4.2203\n",
      "Epoch 497/500 | Avg step duration: 423.37 ms/step | Epoch duration: 2420.73 ms/epoch --> loss: 2.3750 - val_loss: 4.1958\n",
      "Epoch 498/500 | Avg step duration: 424.89 ms/step | Epoch duration: 2408.31 ms/epoch --> loss: 2.2344 - val_loss: 4.2057\n",
      "Epoch 499/500 | Avg step duration: 424.98 ms/step | Epoch duration: 2405.36 ms/epoch --> loss: 2.2500 - val_loss: 4.2204\n",
      "Epoch 500/500 | Avg step duration: 424.97 ms/step | Epoch duration: 2417.75 ms/epoch --> loss: 2.3125 - val_loss: 4.2614\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "gpt2.fit( # type: ignore\n",
    "    data_loader = data_loader,\n",
    "    epochs = epochs,\n",
    "    lr = learning_rate,\n",
    "    batch_size = batch_size,\n",
    "    micro_batch_size = micro_batch_size,\n",
    "    sequence_length = sequence_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "Sangue; e quei, quindi mi rechi\n",
      "dall'altra, dietro, e lei mifova, ed qu torn tal color li, per che quant quel quel da come tut poai quinatt di poatt cost disom fu comel guel sole chel dalle cella drve' venanta quell'ho se quello suca da un chello non credo\n",
      "inciute leatt, e non quella son mella so tu is il fu fu farper tempo per questel quelle son se tut te son la la queta prop te sentinci guardia li qual far te mia passai son questun' tu dimindi, e son vindi ved fu nai torn ben dimai se un chiedi', quella guardai non volora cai pur non dalla per foratt' qual pensai fu son pos sin\n"
     ]
    }
   ],
   "source": [
    "# Encode the context using the tokenizer and convert it to a tensor\n",
    "context = torch.zeros(1, dtype=torch.long).unsqueeze(0).clone().detach()\n",
    "context = context.to(device) # Move the tensor to the GPU if available\n",
    "\n",
    "# Decode and display the generated text\n",
    "print(tokenizer.decode(gpt2.generate(context, max_new_tokens=200).squeeze().tolist())) # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
